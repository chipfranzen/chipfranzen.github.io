<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Charles Franzen</title><link>http://charlesfranzen.com/</link><description>A blog about data, python, and whatever else crosses my mind.</description><atom:link type="application/rss+xml" href="http://charlesfranzen.com/rss.xml" rel="self"></atom:link><language>en</language><lastBuildDate>Thu, 15 Dec 2016 03:54:44 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Time Complexity of Matrix Multiplication</title><link>http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Time-Complexity-of-Matrix-Multiplication"&gt;Time Complexity of Matrix Multiplication&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/#Time-Complexity-of-Matrix-Multiplication"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charles Franzen&lt;/p&gt;
&lt;p&gt;This project investigates the time complexity of different matrix multiplication algorithms. The objectives of the project are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;understand and implement the naive, recursive and strassen algorithms for matrix multiplication&lt;/li&gt;
&lt;li&gt;run experiments to measure the run-time for each algorithm for different sized $n$&lt;/li&gt;
&lt;li&gt;extrapolate from this data to find crossing over points at which one algorithm becomes more efficient than another&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><guid>http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/</guid><pubDate>Wed, 30 Nov 2016 19:39:10 GMT</pubDate></item><item><title>Text Summarizer</title><link>http://charlesfranzen.com/posts/text-summarizer/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Text-Summarizer"&gt;Text Summarizer&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/text-summarizer/#Text-Summarizer"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;h3 id="Overview"&gt;Overview&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/text-summarizer/#Overview"&gt;¶&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This is a text summarizer based loosely on &lt;a href="http://smmry.com/"&gt;SMMRY&lt;/a&gt;. It returns the most important sentences in a document. It works by assigning a score to each sentence in one of 2 ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;summing the tf-idf values of its constituent words OR&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;calculating the distance of each sentence from all the other sentences.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/text-summarizer/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><guid>http://charlesfranzen.com/posts/text-summarizer/</guid><pubDate>Tue, 03 May 2016 03:18:38 GMT</pubDate></item><item><title>Predicting Activities from Accelerometer Data</title><link>http://charlesfranzen.com/posts/predicting-activities-from-accelerometer-data/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Using-accelerometer-data-to-identify-activities"&gt;Using accelerometer data to identify activities&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/predicting-activities-from-accelerometer-data/#Using-accelerometer-data-to-identify-activities"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charles Franzen&lt;/p&gt;
&lt;p&gt;This &lt;a href="http://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer#"&gt;data set&lt;/a&gt; consists of discrete samples of accelerometer data during various types of activities. This is a supervised learning classification task on time series data. I've used scikit-learn, scipy, numpy, and pandas as the core technologies of this analysis.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/predicting-activities-from-accelerometer-data/"&gt;Read more…&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><guid>http://charlesfranzen.com/posts/predicting-activities-from-accelerometer-data/</guid><pubDate>Tue, 26 Apr 2016 13:05:30 GMT</pubDate></item><item><title>Dimensionality Reduction: Identifying numerical candidates for PCA</title><link>http://charlesfranzen.com/posts/dimensionality-reduction-identifying-numerical-candidates-for-pca/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="IDing-numerical-candidates-for-PCA"&gt;IDing numerical candidates for PCA&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/dimensionality-reduction-identifying-numerical-candidates-for-pca/#IDing-numerical-candidates-for-PCA"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;PCA is a powerful way to reduce dimensionality by extracting principal axes of variation from multiple variables. Once highly correlated variables are identified, the largest principal components can be extracted and the smallest discarded.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/dimensionality-reduction-identifying-numerical-candidates-for-pca/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><guid>http://charlesfranzen.com/posts/dimensionality-reduction-identifying-numerical-candidates-for-pca/</guid><pubDate>Wed, 06 Apr 2016 00:51:04 GMT</pubDate></item><item><title>QR factorization using numpy</title><link>http://charlesfranzen.com/posts/qr-factorization-using-numpy/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="QR-factorization---a-Numpy-implementation"&gt;QR factorization - a Numpy implementation&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/qr-factorization-using-numpy/#QR-factorization---a-Numpy-implementation"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;QR factorization factorizes a matrix &lt;strong&gt;A&lt;/strong&gt; into an orthonormal matrix &lt;strong&gt;Q&lt;/strong&gt; and a triangular matrix &lt;strong&gt;R&lt;/strong&gt;.&lt;/p&gt;
$$\textbf{Q}\textbf{R}=\textbf{A}$$&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/qr-factorization-using-numpy/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>linear algebra</category><category>python</category><guid>http://charlesfranzen.com/posts/qr-factorization-using-numpy/</guid><pubDate>Tue, 08 Mar 2016 02:05:02 GMT</pubDate></item><item><title>Presentation: US Visa Application Analysis</title><link>http://charlesfranzen.com/posts/presentation-us-visa-application-analysis/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div&gt;&lt;p&gt;I recently made a presentation on a model that I created to analyze US Work Visa Applications. Click the image below to watch the YouTube video. The companion ipython notebook can be found &lt;a href="http://charlesfranzen.com/posts/machine-learning-classifying-us-visa-applications/"&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=VeECWp_cgKg&amp;amp;feature=youtu.be" title="Capstone Presentation"&gt;&lt;img alt="Click Here" src="https://img.youtube.com/vi/VeECWp_cgKg&amp;amp;feature=youtu.be/0.jpg"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>machine-learning</category><guid>http://charlesfranzen.com/posts/presentation-us-visa-application-analysis/</guid><pubDate>Sun, 07 Feb 2016 11:20:11 GMT</pubDate></item><item><title>Multiple Regression in Python- Gradient Descent</title><link>http://charlesfranzen.com/posts/multiple-regression-in-python-gradient-descent/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Multiple-Regression--Gradient-Descent"&gt;Multiple Regression- Gradient Descent&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/multiple-regression-in-python-gradient-descent/#Multiple-Regression--Gradient-Descent"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As the number of features used in regression increases, the matrix operations required by the closed-form solution become computationaly expensive, if not impossible.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/multiple-regression-in-python-gradient-descent/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>machine-learning</category><category>python</category><category>regression</category><category>statistics</category><guid>http://charlesfranzen.com/posts/multiple-regression-in-python-gradient-descent/</guid><pubDate>Mon, 18 Jan 2016 09:46:22 GMT</pubDate></item><item><title>Markov Chains in Python</title><link>http://charlesfranzen.com/posts/markov-chains-in-python/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Representing-Markov-Chains-in-Python-3"&gt;Representing Markov Chains in Python 3&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/markov-chains-in-python/#Representing-Markov-Chains-in-Python-3"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Markov chains are random processes wherein state-changes occur according to some probablility function.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/markov-chains-in-python/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>statistics</category><guid>http://charlesfranzen.com/posts/markov-chains-in-python/</guid><pubDate>Mon, 11 Jan 2016 13:17:50 GMT</pubDate></item><item><title>Simple Linear Regression in Python</title><link>http://charlesfranzen.com/posts/simple-linear-regression-in-python/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Simple-Linear-Regression--Closed-Form"&gt;Simple Linear Regression- Closed Form&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/simple-linear-regression-in-python/#Simple-Linear-Regression--Closed-Form"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;A Simple Linear Regression fits a line to data points with two dimensions. It does this by defining and then minimizing a cost function. One of the most common methods used is ordinary least squares (OLS), which minimizes the square of the residuals of a line plotted against the data points.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/simple-linear-regression-in-python/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>regression</category><category>statistics</category><guid>http://charlesfranzen.com/posts/simple-linear-regression-in-python/</guid><pubDate>Sat, 02 Jan 2016 03:28:52 GMT</pubDate></item><item><title>Simple Voting Classifier</title><link>http://charlesfranzen.com/posts/simple-voting-classifier/</link><dc:creator>Charles Franzen</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Simple-Voting-Classifier-in-Python"&gt;Simple Voting Classifier in Python&lt;a class="anchor-link" href="http://charlesfranzen.com/posts/simple-voting-classifier/#Simple-Voting-Classifier-in-Python"&gt;¶&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Libraries like Scikit-learn are sometimes equiped with a voting classifier that will allow you to aggregate your machine learning models through voting. If you have a bunch of models already built, though, voting classifiers can take a very long time to build, as each individual model has to be built again by the new classifier.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="http://charlesfranzen.com/posts/simple-voting-classifier/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>classification</category><category>machine-learning</category><category>python</category><guid>http://charlesfranzen.com/posts/simple-voting-classifier/</guid><pubDate>Sat, 26 Dec 2015 03:42:53 GMT</pubDate></item></channel></rss>