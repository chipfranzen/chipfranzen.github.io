<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Time Complexity of Matrix Multiplication | Charles Franzen</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script>
</head>
<body>
<p>
# 
        <!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]-->

    


    

    <meta name="author" content="Charles Franzen"><link rel="prev" href="../text-summarizer/" title="Text Summarizer" type="text/html"><meta property="og:site_name" content="Charles Franzen"><meta property="og:title" content="Time Complexity of Matrix Multiplication"><meta property="og:url" content="http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/"><meta property="og:description" content="Time Complexity of Matrix Multiplication¶Charles Franzen
This project investigates the time complexity of different matrix multiplication algorithms. The objectives of the project are:

understand and"><meta property="og:type" content="article"><meta property="article:published_time" content="2016-12-01T03:39:10+08:00"></p>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://charlesfranzen.com/">

                <span id="blog-title">Charles Franzen</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../index.html">Home</a>
                </li>
<li>
<a href="../../archive.html">Archives</a>
                </li>
<li>
<a href="../../categories/index.html">Tags</a>
                </li>
<li>
<a href="../../rss.xml">RSS</a>
                </li>
<li>
<a href="../../stories/about-me/index.html">About me</a>
                </li>
<li>
<a href="https://www.linkedin.com/in/charles-franz%C3%A9n-40484a24">My Linked-In</a>
                </li>
<li>
<a href="https://github.com/chipfranzen">My Github</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.ipynb" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Time Complexity of Matrix Multiplication</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                    Charles Franzen
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2016-12-01T03:39:10+08:00" itemprop="datePublished" title="2016-12-01 03:39">2016-12-01 03:39</time></a></p>
                <p class="commentline">
        
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/time-complexity-of-matrix-multiplication.html">Comments</a>


            
        </p>
<p class="sourceline"><a href="index.ipynb" id="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Time-Complexity-of-Matrix-Multiplication">Time Complexity of Matrix Multiplication<a class="anchor-link" href="#Time-Complexity-of-Matrix-Multiplication">¶</a>
</h2>
<p>Charles Franzen</p>
<p>This project investigates the time complexity of different matrix multiplication algorithms. The objectives of the project are:</p>
<ul>
<li>understand and implement the naive, recursive and strassen algorithms for matrix multiplication</li>
<li>run experiments to measure the run-time for each algorithm for different sized $n$</li>
<li>extrapolate from this data to find crossing over points at which one algorithm becomes more efficient than another</li>
</ul>
<!-- TEASER_END --><p>Companion code for this project is found <a href="https://github.com/chipfranzen/linalg/blob/master/mat_mul.py">on my github</a>.</p>
<h3 id="Algorithm-overview-and-implementation">Algorithm overview and implementation<a class="anchor-link" href="#Algorithm-overview-and-implementation">¶</a>
</h3>
<p>All of these algorithms calculate the dot product of $A$ and $B$:</p>
$$C = A \cdot B$$<p>For the sake of simplicity, all inputs are restricted to square matrices of dimensions $n\times n$, where $n$ is a power of $2$.</p>
<h4 id="Naive">Naive<a class="anchor-link" href="#Naive">¶</a>
</h4>
<p>The naive algorithm calculates $C$ by calculating $n^2$ dot products of the rows of $A$ and the columns of $B$:</p>
$$C_{ij} = \sum_{k=1}^{n}A_{ik} \cdot B_{kj}$$<p>Pseudocode:</p>

<pre><code>def naive_mat_mul(A, B)
    n = num_rows(A)
    C = new n x n zero matrix
    for i=1 to n:
      for j=1 to n:
        for k=1 to n:
          C_ij += sum(A_ik * B_kj)
    return C</code></pre>
<p>See the implementation in <a href="https://github.com/chipfranzen/linalg/blob/master/mat_mul.py">mat_mul.py</a>.</p>
<p>The nested <code>for</code> loops make it clear that $$\text{naive(}A,\text{ }B) = O(n^3)$$</p>
<h4 id="Recursive">Recursive<a class="anchor-link" href="#Recursive">¶</a>
</h4>
<p>The recursive algorithm subdivides $A$ and $B$ and calculates $C$ as a set of dot products of these partitions.</p>
<p>Partition $A$, $B$, and $C$ in to four $n/2 \times n/2$ matrices:</p>
<p>$A = \begin {bmatrix}
A_{11} &amp; A_{12} \\
A_{21} &amp; A_{22}\end {bmatrix}$, $B = \begin{bmatrix}
B_{11} &amp; B_{12} \\
B_{21} &amp; B_{22}\end {bmatrix}$, $C = \begin {bmatrix}
C_{11} &amp; C_{12} \\
C_{21} &amp; C_{22}\end {bmatrix}$</p>
<p>The equation $C = A \cdot B$ can be rewritten as:</p>
<p>$\begin {bmatrix}
C_{11} &amp; C_{12} \\
C_{21} &amp; C_{22}\end {bmatrix} = \begin {bmatrix}
A_{11} &amp; A_{12} \\
A_{21} &amp; A_{22}\end {bmatrix} \cdot \begin{bmatrix}
B_{11} &amp; B_{12} \\
B_{21} &amp; B_{22}\end {bmatrix}$</p>
<p>which corresponds to these four equations:
$$C_{11} = A_{11} \cdot B_{11} + A_{12} \cdot B_{21}$$
$$C_{12} = A_{11} \cdot B_{12} + A_{12} \cdot B_{22}$$
$$C_{21} = A_{21} \cdot B_{11} + A_{22} \cdot B_{21}$$
$$C_{22} = A_{21} \cdot B_{12} + A_{22} \cdot B_{22}$$</p>
<p>Each of these smaller dot products can be subdivided in the same way, leading to a recursive algorithm (see <a href="https://github.com/chipfranzen/linalg/blob/master/mat_mul.py">mat_mul.py</a>).</p>
<p>Pseudocode:</p>

<pre><code>def recursive_mat_mul(A, B):
    n = num_rows(A)
    C = new n x n zero matrix
    if n == 1:
        C = A * B
    else:
        divide A and B as shown above
        calculate each quadrant of C as shown above
    return C</code></pre>
<p>Note that each call to <code>recursive_mat_mul</code> triggers $8$ further calls. As a result of this property, it can be shown that
$$\text{recursive(}A,\text{ }B) = O(n^{{log}_2 8}) = O(n^3)$$</p>
<h4 id="Strassen">Strassen<a class="anchor-link" href="#Strassen">¶</a>
</h4>
<p>The Strassen algorithm is also recursive, and also works by subdividing $A$, $B$, and $C$. The key difference is that the Strassen algorithm uses a number of matrix <em>additions</em> to reduce the number of <em>multiplications</em> for each call.</p>
<p>Subdivide $A$, $B$, and $C$ as in the recursive algorithm. Then create the following $7$ matrices:</p>
<p>$M_1 = (A_{11} + A_{22}) \cdot (B_{11} + B_{22}) $</p>
<p>$M_2 = (A_{21} + A_{22}) \cdot B_{11}$</p>
<p>$M_3 = A_{11} \cdot (B_{12} - B_{22})$</p>
<p>$M_4 = A_{22} \cdot (B_{21} - B_{11})$</p>
<p>$M_5 = (A_{11} + A_{12}) \cdot B_{22}$</p>
<p>$M_6 = (A_{21} - A_{11}) \cdot (B_{11} + B_{12})$</p>
<p>$M_7 = (A_{12} - A_{22}) \cdot (B_{21} + B_{22})$</p>
<p>Now, $C$ can be derived as additions of these matrices as follows:</p>
<p>$C_{11} = M_1 + M_4 - M_5 + M_7$</p>
<p>$C_{12} = M_3 + M_5$</p>
<p>$C_{21} = M_2 + M_4$</p>
<p>$C_{22} = M_1 - M_2 + M_3 + M_6$</p>
<p>Pseudocode:</p>

<pre><code>def strassen_mat_mul(A, B):
    n = num_rows(A)
    C = new n x n zero matrix
    if n == 1:
        C = A * B
    else:
        divide A and B as in the recursive algorithm
        calcuate the 7 intermediate matrices as shown above
        calculate each quadrant of C as shown above
    return C</code></pre>
<p>See the implementation in <a href="https://github.com/chipfranzen/linalg/blob/master/mat_mul.py">mat_mul.py</a>.</p>
<p>Each call to <code>strassen_mat_mul</code> triggers 7 recursive calls. It can be shown, then, that
$$\text{strassen(}A,\text{ }B) = O(n^{{log}_2 7}) = O(n^{\approx 2.8})$$</p>
<h4 id="Comparison">Comparison<a class="anchor-link" href="#Comparison">¶</a>
</h4>
<p>The naive algorithm is straightforward to understand and implement. There's also very little overhead for each operation. In contrast, the recursive algorithm is a bit harder to understand, and the indexing is tedious. The recursive algorithm also has quite a bit of overhead, as lots of new matrices have to be created in memory, and the relatively complex <code>recursive_mat_mul</code> function has to be called many times, whereas the naive algorithm simply calls <code>A[i, k] * B[k, j]</code> over and over.</p>
<p>The Strassen algorithm has the most overhead, as 7 new matrices and a variety of matrix additions occur for every call. This means that the coefficients on the terms of the asymtotic complexity are quite high. Consequently, it takes a while for the strassen algorithm to overtake an $O(n^{3})$ function with lower coefficients. This means that the cross over points at which the Strassen algorithm becomes more efficient than the naive or recursive algorithms might be at very large $n$.</p>
<h3 id="Measuring-performance-on-my-machine">Measuring performance on my machine<a class="anchor-link" href="#Measuring-performance-on-my-machine">¶</a>
</h3>
<p>In the module <a href="https://github.com/chipfranzen/linalg/blob/master/mat_mul.py">mat_mul.py</a> I provide a function for measuring execution times for different <code>mat_mul</code> functions at different $n$. These experiments take a while to run at large $n$, so 64 is the maximum $n$ that I actually tested on my machine. To account for the precision of my machine's clock and variability in execution time, I've averaged 3000 trials for the naive algorithm, and 300 trials for the recursive and Strassen algorithms.</p>
<p>The results (average execution time in seconds):</p>
<table>
<thead><tr>
<th>n</th>
<th>naive</th>
<th>recursive</th>
<th>strassen</th>
</tr></thead>
<tbody>
<tr>
<td>1</td>
<td>5.99e-06</td>
<td>1.31e-06</td>
<td>1.81e-06</td>
</tr>
<tr>
<td>2</td>
<td>1.61e-05</td>
<td>8.86e-05</td>
<td>9.42e-05</td>
</tr>
<tr>
<td>4</td>
<td>7.79e-05</td>
<td>3.40e-04</td>
<td>4.54e-04</td>
</tr>
<tr>
<td>8</td>
<td>5.15e-04</td>
<td>2.46e-03</td>
<td>3.25e-03</td>
</tr>
<tr>
<td>16</td>
<td>3.65e-03</td>
<td>0.0197</td>
<td>0.0227</td>
</tr>
<tr>
<td>32</td>
<td>0.0290</td>
<td>0.163</td>
<td>0.161</td>
</tr>
<tr>
<td>64</td>
<td>0.225</td>
<td>1.29</td>
<td>1.26</td>
</tr>
</tbody>
</table>
<p><img src="../../images/execution_time3.png" alt="times"></p>
<p>At first, the naive algorithm grows much more slowly than the recursive and Strassen algorithms. In fact, the Strassen algorithm has the worst performance of the 
three for small $n$.</p>
<h3 id="Extrapolate-to-estimate-cross-over-points">Extrapolate to estimate cross-over points<a class="anchor-link" href="#Extrapolate-to-estimate-cross-over-points">¶</a>
</h3>
<p>By fitting a polynomial regression line to each set of data points, cross-over points can be estimated for these approaches to matrix multiplication.</p>
<p>The crossover point for the recursive and strassen algorithms is fairly early, at just $n=32$, and is shown in the experimental data. Finding a crossover point for the naive and strassen algorithms was a little trickier.</p>
<p>The fitted regression models have very small coefficients for the $n^3$ and $n^{{log_27}}$ terms. Here is a plot of the models up to $n=1024$:</p>
<p><img src="../../images/regressions.png" alt="regression"></p>
<p>I timed a <code>1024 x 1024</code> multiplication for the naive and strassen methods, and the times (<code>~17m</code> and <code>~45m</code>, respectively) matched the regression predictions fairly closely. A back of the envelope calculation for a crossover point led to an estimate of around $n=$ <code>3e14</code> for the point at which the strassen algorithm outperforms the naive. Obviously, this result was a bit disappointing, as I'd hoped to find that the strassen algorithm caught up to the naive fairly quickly. It seems that Python implementations involve too much overhead to benefit from the lower computational complexity of the strassen algorithm. I tried a couple different versions of the strassen algorithm, but wasn't able to improve execution time this way. Most of the papers that I read on this topic involved code written in C or Java. These researchers were able to find crossover points ranging from $n=450$ to $n=1024$.</p>
<h3 id="References">References<a class="anchor-link" href="#References">¶</a>
</h3>
<ul>
<li>
<p>Cormen, Thomas H., and Charles E. Leiserson. Introduction to Algorithms, 3rd Edition. Cambridge: MIT, 2009. p. 75-82</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Strassen_algorithm">https://en.wikipedia.org/wiki/Strassen_algorithm</a></p>
</li>
<li>
<p>D’Alberto, Paolo, and Alexandru Nicolau. "Using Recursion to Boost ATLAS’s Performance." High-Performance Computing Lecture Notes in Computer Science (n.d.): 142-51. <a href="https://www.ics.uci.edu/~paolo/Reference/paoloA.ishp-vi.pdf">https://www.ics.uci.edu/~paolo/Reference/paoloA.ishp-vi.pdf</a></p>
</li>
<li>
<p>Bailey, David H., King Lee, and Horst D. Simon. "Using Strassen's Algorithm to Accelerate the Solution of Linear Systems." The Journal of Supercomputing 4.4 (1991): 357-71. <a href="http://crd-legacy.lbl.gov/~dhbailey/dhbpapers/strassen.pdf">http://crd-legacy.lbl.gov/~dhbailey/dhbpapers/strassen.pdf</a></p>
</li>
<li>
<p>Mathew, Juby, and R. Vijaya Kumar. "Comparative Study of Strassen’s Matrix Multiplication Algorithm." International Journal of Computer Science And Technology 3.1 (2012): 749-54. <a href="http://www.ijcst.com/vol31/4/juby.pdf">http://www.ijcst.com/vol31/4/juby.pdf</a></p>
</li>
</ul>
</div>
</div>
</div>
    </div>
  </div>

    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../text-summarizer/" rel="prev" title="Text Summarizer">Previous post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
        
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="charlesfranzen",
            disqus_url="http://charlesfranzen.com/posts/time-complexity-of-matrix-multiplication/",
        disqus_title="Time Complexity of Matrix Multiplication",
        disqus_identifier="cache/posts/time-complexity-of-matrix-multiplication.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script>
# 

</article><script>var disqus_shortname="charlesfranzen";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2016         <a href="mailto:chip.franzen@gmail.com">Charles Franzen</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
<img alt="Creative Commons License
style=" border-width:0 src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a>
<br>This work by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Charles Franzen</span> is licensed under a
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License
</a>.
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
